{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming the MNIST CSV file is in the 'data' folder within your project\n",
    "mnist_df = pd.read_csv('data/mnist_train.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features and labels\n",
    "X = mnist_df.iloc[:, 1:].values  # All pixel values\n",
    "y = mnist_df.iloc[:, 0].values   # Labels\n",
    "\n",
    "# Reshape the features (images) into 2D array with 784 columns\n",
    "X_reshaped = X.reshape(X.shape[0], 28 * 28)\n",
    "\n",
    "# Select only 1,000 samples from the dataset for simplicity\n",
    "X_sample = X_reshaped[:1000]\n",
    "y_sample = y[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: (900, 784), Validation set size: (100, 784)\n"
     ]
    }
   ],
   "source": [
    "# Manually split the dataset into 90% train and 10% validation\n",
    "split_index = int(0.9 * X_sample.shape[0])\n",
    "X_train, y_train = X_sample[:split_index], y_sample[:split_index]\n",
    "X_val, y_val = X_sample[split_index:], y_sample[split_index:]\n",
    "\n",
    "print(f\"Training set size: {X_train.shape}, Validation set size: {X_val.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Function to calculate Euclidean distance\n",
    "def euclidean_distance(x1, x2):\n",
    "    return np.sqrt(np.sum((x1 - x2) ** 2))\n",
    "\n",
    "# KNN classifier\n",
    "def simple_knn(X_train, y_train, x_test, k=3):\n",
    "    distances = []\n",
    "    \n",
    "    # Calculate the distance from the test point to each training point\n",
    "    for i in range(len(X_train)):\n",
    "        distance = euclidean_distance(X_train[i], x_test)\n",
    "        distances.append((distance, y_train[i]))\n",
    "    \n",
    "    # Sort distances by the first element (distance), and take the k nearest neighbors\n",
    "    distances.sort(key=lambda x: x[0])\n",
    "    neighbors = distances[:k]\n",
    "    \n",
    "    # Extract the labels of the nearest neighbors\n",
    "    labels = [neighbor[1] for neighbor in neighbors]\n",
    "    \n",
    "    # Return the most common label\n",
    "    most_common = Counter(labels).most_common(1)\n",
    "    return most_common[0][0]\n",
    "\n",
    "# Testing KNN with validation set\n",
    "def predict_knn(X_train, y_train, X_val, k=3):\n",
    "    y_pred = []\n",
    "    for x_test in X_val:\n",
    "        label = simple_knn(X_train, y_train, x_test, k=k)\n",
    "        y_pred.append(label)\n",
    "    return y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 88.00%\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the validation set\n",
    "k = 3\n",
    "y_pred = predict_knn(X_train, y_train, X_val, k=k)\n",
    "\n",
    "# Calculate accuracy\n",
    "def accuracy(y_true, y_pred):\n",
    "    correct = 0\n",
    "    for i in range(len(y_true)):\n",
    "        if y_true[i] == y_pred[i]:\n",
    "            correct += 1\n",
    "    return correct / len(y_true)\n",
    "\n",
    "# Calculate and print accuracy\n",
    "acc = accuracy(y_val, y_pred)\n",
    "print(f\"Validation Accuracy: {acc * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 82.40%\n"
     ]
    }
   ],
   "source": [
    "#test part\n",
    "# Load the test dataset\n",
    "test_mnist_df = pd.read_csv('data/mnist_test.csv')\n",
    "\n",
    "X_test = test_mnist_df.iloc[:, 1:].values\n",
    "y_test = test_mnist_df.iloc[:, 0].values[:1000]\n",
    "\n",
    "# Reshape the test set (flatten 28x28 images into vectors of size 784)\n",
    "X_test_reshaped = X_test.reshape(X_test.shape[0], 28 * 28)[:1000]\n",
    "\n",
    "k = 4\n",
    "y_test_pred = predict_knn(X_train, y_train, X_test_reshaped, k=k)\n",
    "\n",
    "test_accuracy = accuracy(y_test, y_test_pred)\n",
    "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final training set size: (1000, 784)\n"
     ]
    }
   ],
   "source": [
    "X_train_final = np.vstack((X_train, X_val))\n",
    "y_train_final = np.hstack((y_train, y_val))\n",
    "\n",
    "print(f\"Final training set size: {X_train_final.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def manhattan_distance(x1, x2):\n",
    "    return np.sum(np.abs(x1 - x2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN classifier with an option for distance metric\n",
    "def knn(X_train, y_train, x_test, k=3, distance_metric='euclidean'):\n",
    "    distances = []\n",
    "    \n",
    "    # Calculate the distance from the test point to each training point\n",
    "    for i in range(len(X_train)):\n",
    "        if distance_metric == 'euclidean':\n",
    "            distance = euclidean_distance(X_train[i], x_test)\n",
    "        elif distance_metric == 'manhattan':\n",
    "            distance = manhattan_distance(X_train[i], x_test)\n",
    "        distances.append((distance, y_train[i]))\n",
    "    \n",
    "    # Sort distances by the first element (distance), and take the k nearest neighbors\n",
    "    distances.sort(key=lambda x: x[0])\n",
    "    neighbors = distances[:k]\n",
    "    \n",
    "    # Extract the labels of the nearest neighbors\n",
    "    labels = [neighbor[1] for neighbor in neighbors]\n",
    "    \n",
    "    # Return the most common label\n",
    "    most_common = Counter(labels).most_common(1)\n",
    "    return most_common[0][0]\n",
    "\n",
    "def predict_knn(X_train, y_train, X_val, k=3, distance_metric='euclidean'):\n",
    "    y_pred = []\n",
    "    for x_test in X_val:\n",
    "        label = knn(X_train, y_train, x_test, k=k, distance_metric=distance_metric)\n",
    "        y_pred.append(label)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy (Euclidean Distance): 85.00%\n",
      "Test Accuracy (Manhattan Distance): 83.33%\n"
     ]
    }
   ],
   "source": [
    "y_test_pred_euclidean = predict_knn(X_train_final, y_train_final, X_test_reshaped, k=3, distance_metric='euclidean')\n",
    "\n",
    "y_test_pred_manhattan = predict_knn(X_train_final, y_train_final, X_test_reshaped, k=3, distance_metric='manhattan')\n",
    "\n",
    "# Calculate accuracy for both Euclidean and Manhattan distances\n",
    "accuracy_euclidean = accuracy(y_test, y_test_pred_euclidean)\n",
    "accuracy_manhattan = accuracy(y_test, y_test_pred_manhattan)\n",
    "\n",
    "print(f\"Test Accuracy (Euclidean Distance): {accuracy_euclidean * 100:.2f}%\")\n",
    "print(f\"Test Accuracy (Manhattan Distance): {accuracy_manhattan * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=1: Euclidean Accuracy = 83.67%, Manhattan Accuracy = 82.67%\n",
      "k=2: Euclidean Accuracy = 83.67%, Manhattan Accuracy = 82.67%\n",
      "k=3: Euclidean Accuracy = 85.00%, Manhattan Accuracy = 83.33%\n",
      "k=4: Euclidean Accuracy = 86.00%, Manhattan Accuracy = 83.33%\n",
      "k=5: Euclidean Accuracy = 85.33%, Manhattan Accuracy = 82.00%\n",
      "k=6: Euclidean Accuracy = 85.33%, Manhattan Accuracy = 82.00%\n",
      "k=7: Euclidean Accuracy = 83.33%, Manhattan Accuracy = 82.00%\n",
      "k=8: Euclidean Accuracy = 84.33%, Manhattan Accuracy = 81.67%\n",
      "k=9: Euclidean Accuracy = 83.00%, Manhattan Accuracy = 80.00%\n",
      "k=10: Euclidean Accuracy = 83.67%, Manhattan Accuracy = 80.00%\n"
     ]
    }
   ],
   "source": [
    "# Ø¬\n",
    "\n",
    "# Experimenting with different values of k\n",
    "for k in range(1, 11):\n",
    "    y_test_pred_euclidean = predict_knn(X_train_final, y_train_final, X_test_reshaped, k=k, distance_metric='euclidean')\n",
    "    y_test_pred_manhattan = predict_knn(X_train_final, y_train_final, X_test_reshaped, k=k, distance_metric='manhattan')\n",
    "    \n",
    "    acc_euclidean = accuracy(y_test, y_test_pred_euclidean)\n",
    "    acc_manhattan = accuracy(y_test, y_test_pred_manhattan)\n",
    "\n",
    "    # We can break the loop when then accuracy is decreasing (higher complicated model -> higher cahnce of overfit)\n",
    "    \n",
    "    print(f\"k={k}: Euclidean Accuracy = {acc_euclidean * 100:.2f}%, Manhattan Accuracy = {acc_manhattan * 100:.2f}%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy (Euclidean Distance): 97.05%\n",
      "Test Accuracy (Manhattan Distance): 96.33%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Separate features and labels for both train and test datasets\n",
    "X_train = mnist_df.iloc[:, 1:].values  # Pixel values (features)\n",
    "y_train = mnist_df.iloc[:, 0].values   # Labels\n",
    "\n",
    "X_test = test_mnist_df.iloc[:, 1:].values    # Pixel values (features)\n",
    "y_test = test_mnist_df.iloc[:, 0].values     # Labels\n",
    "\n",
    "# Reshape the data as needed (already in 2D format, so no reshape needed)\n",
    "\n",
    "# KNN with Euclidean distance\n",
    "knn_euclidean = KNeighborsClassifier(n_neighbors=3, metric='euclidean')\n",
    "knn_euclidean.fit(X_train, y_train)\n",
    "\n",
    "# Predict using Euclidean distance\n",
    "y_test_pred_euclidean = knn_euclidean.predict(X_test)\n",
    "\n",
    "# Calculate accuracy for Euclidean distance\n",
    "accuracy_euclidean = accuracy_score(y_test, y_test_pred_euclidean)\n",
    "print(f\"Test Accuracy (Euclidean Distance): {accuracy_euclidean * 100:.2f}%\")\n",
    "\n",
    "\n",
    "# KNN with Manhattan distance\n",
    "knn_manhattan = KNeighborsClassifier(n_neighbors=3, metric='manhattan')\n",
    "knn_manhattan.fit(X_train, y_train)\n",
    "\n",
    "# Predict using Manhattan distance\n",
    "y_test_pred_manhattan = knn_manhattan.predict(X_test)\n",
    "\n",
    "# Calculate accuracy for Manhattan distance\n",
    "accuracy_manhattan = accuracy_score(y_test, y_test_pred_manhattan)\n",
    "print(f\"Test Accuracy (Manhattan Distance): {accuracy_manhattan * 100:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
